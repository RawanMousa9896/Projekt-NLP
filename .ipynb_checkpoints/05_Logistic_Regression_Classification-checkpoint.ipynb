{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faa6a384",
   "metadata": {},
   "source": [
    "# Classify the films using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29e5775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab932032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>release_year</th>\n",
       "      <th>language</th>\n",
       "      <th>genre</th>\n",
       "      <th>overview</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>popularity</th>\n",
       "      <th>cleaned_overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pad Man</td>\n",
       "      <td>2018</td>\n",
       "      <td>Indisch</td>\n",
       "      <td>Humor</td>\n",
       "      <td>upon realizing extent woman affected menses se...</td>\n",
       "      <td>7.420</td>\n",
       "      <td>200.0</td>\n",
       "      <td>7.036</td>\n",
       "      <td>upon realizing extent woman affected menses se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tamasha</td>\n",
       "      <td>2015</td>\n",
       "      <td>Indisch</td>\n",
       "      <td>Humor</td>\n",
       "      <td>meeting vacation ved tara sense connection vow...</td>\n",
       "      <td>6.720</td>\n",
       "      <td>141.0</td>\n",
       "      <td>8.770</td>\n",
       "      <td>meeting vacation ved tara sense connection vow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tu Jhoothi Main Makkaar</td>\n",
       "      <td>2023</td>\n",
       "      <td>Indisch</td>\n",
       "      <td>Humor</td>\n",
       "      <td>earn extra cash mickey help couple break life ...</td>\n",
       "      <td>6.253</td>\n",
       "      <td>144.0</td>\n",
       "      <td>10.045</td>\n",
       "      <td>earn extra cash mickey help couple break life ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindi Medium</td>\n",
       "      <td>2017</td>\n",
       "      <td>Indisch</td>\n",
       "      <td>Humor</td>\n",
       "      <td>mita raj batra affluent couple delhi chandni c...</td>\n",
       "      <td>7.300</td>\n",
       "      <td>166.0</td>\n",
       "      <td>7.001</td>\n",
       "      <td>mita raj batra affluent couple delhi chandni c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dilwale</td>\n",
       "      <td>2015</td>\n",
       "      <td>Indisch</td>\n",
       "      <td>Humor</td>\n",
       "      <td>raj mafia member one day meet girl meera chasi...</td>\n",
       "      <td>6.648</td>\n",
       "      <td>301.0</td>\n",
       "      <td>11.501</td>\n",
       "      <td>raj mafia member one day meet girl meera chasi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title  release_year language  genre  \\\n",
       "0                  Pad Man          2018  Indisch  Humor   \n",
       "1                  Tamasha          2015  Indisch  Humor   \n",
       "2  Tu Jhoothi Main Makkaar          2023  Indisch  Humor   \n",
       "3             Hindi Medium          2017  Indisch  Humor   \n",
       "4                  Dilwale          2015  Indisch  Humor   \n",
       "\n",
       "                                            overview  vote_average  \\\n",
       "0  upon realizing extent woman affected menses se...         7.420   \n",
       "1  meeting vacation ved tara sense connection vow...         6.720   \n",
       "2  earn extra cash mickey help couple break life ...         6.253   \n",
       "3  mita raj batra affluent couple delhi chandni c...         7.300   \n",
       "4  raj mafia member one day meet girl meera chasi...         6.648   \n",
       "\n",
       "   vote_count  popularity                                   cleaned_overview  \n",
       "0       200.0       7.036  upon realizing extent woman affected menses se...  \n",
       "1       141.0       8.770  meeting vacation ved tara sense connection vow...  \n",
       "2       144.0      10.045  earn extra cash mickey help couple break life ...  \n",
       "3       166.0       7.001  mita raj batra affluent couple delhi chandni c...  \n",
       "4       301.0      11.501  raj mafia member one day meet girl meera chasi...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"data/movies_2015_2023_preprocessed_genre.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "991b932f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title               0\n",
      "release_year        0\n",
      "language            0\n",
      "genre               0\n",
      "overview            0\n",
      "vote_average        0\n",
      "vote_count          0\n",
      "popularity          0\n",
      "cleaned_overview    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Remove lines that contain NAN-Values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Check whether there are still missing values\n",
    "print(df_cleaned.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10acaf61",
   "metadata": {},
   "source": [
    "Define features and goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6398a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features (cleaned_overview, genre, title) and the goal (language)\n",
    "X = df_cleaned['cleaned_overview'] + ' ' + df_cleaned['genre'] + ' ' + df_cleaned['title']\n",
    "y = df_cleaned['language']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e46d488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into training and test sets (80% training, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff38da4",
   "metadata": {},
   "source": [
    "Feature Engineering: CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "340a64fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CountVectorizer for Bag-of-Words\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "\n",
    "# Convert the text into numerical features (Bag-of-Words)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5a56f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    }
   ],
   "source": [
    "# Define the model and the parameters for the Grid Search\n",
    "log_reg = LogisticRegression(max_iter=2000)\n",
    "\n",
    "param_grid_reduced = [\n",
    "    {'penalty': ['l1', 'l2'], 'C': [1, 10, 100], 'solver': ['liblinear']},\n",
    "    {'penalty': ['elasticnet'], 'C': [1, 10, 100], 'solver': ['saga'], 'l1_ratio': [0, 0.5, 1]}\n",
    "]\n",
    "\n",
    "# Apply grid search\n",
    "grid_search_reduced = GridSearchCV(log_reg, param_grid_reduced, cv=5, verbose=1)\n",
    "grid_search_reduced.fit(X_train_vec, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7d9e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the test set\n",
    "y_pred = grid_search_reduced.predict(X_test_vec)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7ba215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a classification report\n",
    "classification_report_result = classification_report(y_test, y_pred)\n",
    "print(classification_report_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9e3242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=grid_search_reduced.classes_, \n",
    "            yticklabels=grid_search_reduced.classes_)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73afaf10",
   "metadata": {},
   "source": [
    "TF-IDF (Term Frequency-Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f042377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into training and test sets (80% training, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4ff65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0c642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model and the parameters for the Grid Search\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "param_grid_reduced = [\n",
    "    {'penalty': ['l1', 'l2'], 'C': [1, 10, 100], 'solver': ['liblinear']},\n",
    "    {'penalty': ['elasticnet'], 'C': [1, 10, 100], 'solver': ['saga'], 'l1_ratio': [0, 0.5, 1]}\n",
    "]\n",
    "\n",
    "# Apply grid search\n",
    "grid_search_reduced = GridSearchCV(log_reg, param_grid_reduced, cv=5, verbose=1)\n",
    "grid_search_reduced.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9717908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the test set\n",
    "y_pred = grid_search_reduced.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f6ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=grid_search_reduced.classes_, \n",
    "            yticklabels=grid_search_reduced.classes_)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf652afe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
